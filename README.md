# Project 4: Real-Time Data streaming with Kafka and MongoDB

## Objective
simulate real-time data streaming using Kafka integrating with 2 databases: MongoDB and PostgreSQL. The dataset is 2 CSV files:
- Old_Information.csv – contains historical data, stored in PostgreSQL.
- New_Information.csv – represents new transaction data, streamed via Kafka as a message broker.
A machine learning model is then applied to predict whether each transaction is fraudulent.

## Tools:
- PostgreSQL (local server)
- MongoDB (local server) and MongoDB Compass: Ref how to install on windows (https://www.geeksforgeeks.org/how-to-install-mongodb-on-windows/)
- Apache Kafka (local) : Ref how to install on windows (https://www.youtube.com/watch?v=heXd6JA2TQc)
- DBeaver
- Visual Studio Code

